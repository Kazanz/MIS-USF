Class 3: August 29th 2016


Step 6:

Us e the model for prediction/esimation
predict fire damage (y) for a single home that has distance from station(x) of 3.5 miles
Estimate mean fire damage, E(y) for all homes a radius of x=3.5 miles form the station

There is a difference between predicted value and estimated mean value. (How confidence are we based on the width of the confidence interval)

CI and PI formulas (dont have to memorize them)
THe PI can never be narrower than the CI.  
CI == Confidence Interval (the mean of all homes)
PI == Prediction Inteval (the prediction for one observation)

You will specify to sas what value of x you want.   As well as all the other data in your dataset.
Add an observation but leave the known y value out to get the prediction. (SAS trick)

If you were to repeatadly take n samples. 95% of them would contain the true Y value.

95% CL Predict (prediction interval) - 95% CL Mean (mean interval)

### Regression thru the origin

When x is zero you know y is zero.

Origin: y=0 when x=0 -> y-intercept, Bo = 0
string line model: R2 = 1 - sum(y - yhat)^2 / sum(y^2)
Caveat 1: Not comparable to model with y-intercept (R squared calculation is different so you cannot compare them to other models)
Caveat 2: Even if, in theory, y=0 when x=0 best fitting line may not go thru the origin (0,0) may be outside range of sample data

**Do not make predictions outside of range of sample data!**

29% of new PI cases can be explained by the model.

s = 95% of y fall within s*2 of predicted value.

### Chapter 4: Multiple Regression

Multiple independent variables (IVs)
x1, x2, x3, x4, ..., xk
IVS can be quantitative (QN) or qualitative (QL)
E(y) = Bo + b1x1 + B2x2 ..... Bkxk

"linear" models require linear in the betas
Terms OK: B2(x1)^2, B3x1x2
Not linear x1^B1

Method of Least Squares (MLS)
1) Average error of prediction = 0
2) Minimize SSE = sum(y - yhat)^2
Matric Algebra

A matrix is an arranged table of numbers
vector == a one column matrix

y = [y1, y2, yn] x = [[1, x11, x21, ..., xkn], [1, x12, x22, ... xk2], ...]  Bhat = [bhat0, bhat1, bhat2]

x = columns are nthe number of values you have
standard errors comes from the (x(prime) * x)^-1

Testing MR model Adequacy
E(y) = Bo + B1x+ etc...
T-test approach:
Conduct 10 tests Ho: Bi = 0 each at type1 = .05
compounding error
P(at least 1 Type 1 error) = 10 alpha = .50 
F-test approach:
Instead of testing if each values beta is equal to zero.  Test if all values are equal to zero.
Conduct 1 test, H0: b1 = b2 = ... = 0 vs Ha: At least 1 B != o
P(Type I error) = alpha = .05
Test statistic F = MS(Model)/MSE = "explained" varience / "unexplained" varience
Large F value lets you reject the null hypothesis.
F test says hey our model could be useful, but cannot say which one of these variables is useful.
coeffcient of Determination

Do not compare F values, because the F value is derived form degrees of freedom and sample size.

Coefficient of Determination, R^2
Adjusted Coefficient of Determination R^2 adj.
Adjusted R squard cannot be artificially inlfated by adding x variables to the model.

Example: DV: y = Price of condo unit ($ hundreds)
Variables:
x1: floor height (1, 2, 3..., 8)
x2: distance from elevator (1, 2, 3, ..., 15)
x3: View (1 if ocean, 0 if not)
x4: End unity (1 if end, 0 if not)
x5: Furnished (1 if furnished, 0 if not)

These are first-order model (each x is only raised to the first power)

mean squared is a fancy term for variance in Y.

ROOT MSE is the standard deviation you can predict price to withing 20,000 of its true value.
Coeff of variation (Coeff Var) 5% (most researchers like 10% or less)

P value is that the x value is linearly related to the y value and independent of the other x values.

This initial test is a first model, NOT the last model.

epsilon ~iid N(o, standard-error^2)

Is number of bidders more important of a predictor than age.  Yes because even with the wider confidence interval its increase is till greater thatn the max increase of age.
