The elements of Statistical Learning
Machine Learning - Tom M Mitchel

Look at everyone elses posts.  Just skim through, and if something catches your eye, post something.

# Classification: Evaluating Highly Skewed Data

When one class is more common than another you have skeewed classifiers.
Highly skewed data sets

Data sets can either be balanaced or skewed.

When skewed:
   How do we evaluate the data.
   What to do before modeling.

In many skewed data cases, we are usually most interested in the lowest frequency class.

## Confusion Matrix:

   a    b
a  100  10

b  5    20

The following are not measuing the false positives:

True Positive Rate: Of all the positives how many were correctly identified as positive
True Negative Rate: Of all the negatives how many were correctly identified as negative
False Positive Rate: 1 - TNR
False Negative Rate: 1 - TPR 
False positive/negative rate in 1 - True negative/positive

Of all the negatives how many are you falsley calling as positive.

## Cost Matrix (Cost-based numbers):

Same as a confusion matrix except you put a cost on the False positive/negatives

##  Lift Curves (ROC_Curves)

## Ways of injecting bias

Bias a classfier to predict more of a specific value.
by injecting a bias.

*Make sure you have a good evaluation process*

over-sampling: Make a bunch of copies of the minority rows.
under-sampling: Take out a bunch of the majority rows.  Undersampling is done often in industry (JP morgan, etc)

# Decision Trees

"Induction" means learning general rules from specific facts or examples you are given.

"Recursion" in "Recursive Paritioning"

## Estimating "goodness" of a node

- What is the probability of selecting two of the same items.  Assuming sampling with replacement
- Gini Index: 1 - probablity sampling
- Entropy: instead of p1^2 + p2^2 etc.  p1*log(p1) + ...

Trees will not work well on datasets where the independent variables have a relationship to each other.
Another words, angular splits.

Pros:
easy to understand and often very accurate.
learns non-linear relationships.
map nicely to set of business rules.
make no prior assumptions about the data.
able to process both numerical and categorical data.

Disadvantages:
Abliy to model global linear relationships
Trees created can be very deep and complex
Decision tree algorityms can be unstable:
- Different trees on slightly different data

Monotonic (as x1 increases so does the transformations(x1)) transformations will not help with decision trees.
It will still do the same split.


