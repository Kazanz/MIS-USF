# Data analytics in security

## Trying to use analytics to find Human-Trafficking.

Went to a website with a bunch of adult adds. 
Took a bunch of text from postings and applied a classifier to see if we could detect human trafficking.
HOw do you get the "labels"?
They had two expert coders (a person in the FBI, second was a Victim) and they made the "labels".
They had some pretty decent results.

Most of the new work was on creating the features from the ad.
Could they show what the human labelers did in terms of overlap.
200 ads being labeled.  The FBI labeled 30 as trafficking, the victim labeled 120 as trafficking.
They used the intersection.


Communications of the ACM (looking at pulbically available shipping data between countries)
If the item shipped was cotton they got the market value of the cotton and the bill of lading shows a different value than the markey value.
Used for laundering

Bad money to good money.
In New York there are lots of coffee shops in the expensive neiborhoods.
Maybe 100 people coming but they make a profit from reporting nefarious income.

## Find terrorists by looking at forum posting

How do you identify the posts that could be related to terrorist groups.
They identified 3 maganizes known to be related to ISIS, Al-Quida propoganda.
Took text from those maganizes and created classifiers that were then run on forum postings.
Claimed that they could find a bunch of forum postings.

They had articles that were linked to terrorists, but they didnt use maganizes not related to terrorists to eliminate false positives.

You will see an increase in info security analytics. (especially for making some cash selling to law enforcement)

Palantir is one of the most advanced military defence companies. Even bigger than IBM.


# Naive Bayesian classifier

## Motivation

Lets say you encounter a new person
Gender = Male. Whats the Risk.
P(Risk | Gender)
P(Risk = High and Gender = Male) / P(Gender = Male)

P(A|B) == P(A, B) / P(B) ==  P(B|A) / P(B) * P(A)
P(A, B) != P(A) * P(B)  This is only true if they are absolutely independent of each other.

## Bayes extended to many variable

Assume x1, x2, xN are your explanatory variables and Y is the variable being modeled.
Bayes says:

P(Y|X1, X2, ..., Xn) == P(X1, X2, ..., Xn | Y) * P(Y) / P(X1, X2, ..., Xn) == scalingfactor * P(X1, X2, ..., Xn | Y) * P(Y)

When we want to computer P(Risk = high, X1, ..., X100) the denominator is exactly the same, so we can ignore it and replace it by a scaling factor.

## Enter Naive Bayes

Essentially acting as if the X variables were "conditionally independent" of each other.  Meaning, given a value for Y the probability of X3 is no independent of X7 and all other variables.
Formally the conditional indpenedence assumption states that P(Xi | Y, Xj) == P(Xi | Y) when i and j are different.
hence it makes: 
P(Y | X1, ..., Xn) == scalingfactor * P(X1 | Y) * ... * P(Xn| Y) * P(Y)


#---


Entity extraction: Strip out all the nouns (long term profile 1 year) and a short term profile (for the last week).
Doing pariwise comparison of articles nouns with the long or short term profile will tell us what article would be a good suggestion.
Better defined on Click-Thru rates
Come up with the best recomendations, hack out the top articles because people had already read the top articles in the morning.

Shodan.io

In store analytics are very mideval right now and there is a big gap in the market.
