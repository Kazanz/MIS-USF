Query Processing
================

cost: Relative metric

single processor centralized - I/O cost (Tradional dbs)
parallel process w centrailized = I/O costs + Computations costs
Sinle process w distributed db = I/O Costs and Communication Costs

Codd in the 1970s developed the Relational Model. In early days performance was a critical challenge.

## Query Optimization
Findin efficient executions plans for easily written queries was the key to practical use.

## Tradeoff:
Simplicity of use for computing power

## Activities involved in query processing:
Translations of queries in high-level languages, that can be implemented at the physical level of the file system, a variety of query optimizin transformations, and actual evalu of queries.

A execution plan must be generated by the database for a high level language eg SQL.
The query specification may not be specific

# Query Cost

How do we measure the query cost?
We need reasonable cost estimates for the optimizer to make a good plan seelction
- I/O Cost (Magnetic Disk)
- Computation Cost (CPU Use)
- Communication Cost (Network Traffic) *You cannot test the same data on two different servers.**

Other factors?
- Memory Buffer ize, Number of CPUs, Sotrage Architecture, Data Distribution, Network Speeds, Traffic Patterns, Query Selectivity...

The cost is an estimated value proportional to the expected resource use needed to execute the staetment with a particular plan.  The optimizer calulate the cost of access paths and join orders based on the estimated computer resources,
which includes I/O, CPU, etc.

## Progress

Optimizer quality has been a focus of vendor competition.

To reduce the potential for unplanned full table scans, you should avoid, using the CHOOSE option; either use the RBO or CBO throughout your ddatabases [Oracle the complete reference 1997].

Attention: In general you should always use the cost-based optimization approach.  The rule-bases approach is available for the benifi of existing applications, but all new optimizer functionality uses the cost-based approach.
Rule-base apprach is not based on any historical data.
Cost based approach is based on previous history. (much better than rule-based approach)


Hueristics: Do the multiplication first then the division.

# Path
Hi-level query -> parser & translator -> Optimizer (translates what to how) -> Database engine

# Rule-Based Optimization (RBO)
Rule based approached were the first and simplest optimization technique
Reorder the operations (qury tree) by applygin a set of heuristic rules
- Operations that reduct intermediate results are performed as early as possible
- SELECT reduces the number of rows.
- PROJECT reduces the number of columns.
- Join smaller tables frist to reduce temp table sized.
- The most restrictive SELECT and JOIN operations are applied first.

# Cost-Bases Optimization
Generally chooses the execution plan that is as good as or better than the plan chosedn by the RBO.
This is because it depends on the availability of the current db stats.


Microsoft SQL server 2008 collects stats about individual columns (single column stats) or sets of columns.
Stats are used by the query optimizer to estimate the selectivity of expressoin and thus the size of intermediate and final query restuls. 
Good stats allow the optimizer to accutaely assess the cost of different query plans then choose a high quality plan.
Has patented tech for estimating the selectivity of LIKE conditions.  It builds a statitisal summary of sibtring frewency distrinbtion of character columns ( A string summary). 
Using the string summary, sql server can accurately estimate the selecitivy of LIKE condidionts where the pattern may have any number of wild card combinations.

If retrieving more than 20% of data then it does not make sense to retrieve via an index.  Might as well do a full table scan.

**Selectivity**: Determine how much of a table the query is going to return.

Execution plans are the procedural steps generated from the declarative query.

# Execution Plans
Breaks the down the complete plan for how a query will be executed.
Always read from the bottom up.
Database tools almost always expose executions plans for query tuning.
They can be visualized as query trees.

RBO you do divde then multiply.

# Implmentation

Table Access:
- Full table scan
- Table acces by Row Id
Index Access:
- Index Unique Scan
- Index Range Scan
- + Table Access

Database Operations
There is a fundamental difference between basic "seek" and "scan" operations.
Seek you come across one value.
Scan will come across a leag then traversing horizontally.
Sorting

SELECT Processing

Linear Search /Scan (unordered)
- Brute force approach
Binary Search (ordered)
- better but not often used
Primary Index / Key Equality
- Single Row
Primary Index / Nonkey Equality
- multiple rows
Secondary Index / Equality
- Single or Multiple rows

Complex SELECT processing
Conjunctive SELECT usong singel index
Conjunctive SLEECT using composite index

Conjuctive SELECT by INTERSECTION
- use availble indexx
- Take the intersectoin
- Test for remaining theta i

Dijunctive SELECT by UNION
- missin indexes require linear scan.

Optimizer will try to use index as much as possible (Particularly composite index)

Joins are among the most time-consuming operations that a database engine performs

1. Nested-Loop Join
Scans every pair of tuples (memory resident)
Block nested loop join for large tables
Cache innder table or use and index?
m * n (Brute force approach)

2. Block Nested-Loop Join
3. Indexed Nested-Loop Join
If indexes are available for both tables use smaller table in the outer loop.

4. Hash Join
Paritioning Phase 
- Perform a single pass over the smaller table using the join attribute to construct memory-resident hash buckets
Probing phase
- Perform a single pass over the larger table hashing on the join attribute and probing/searching the previsouly formed buckets.
5. Sort-Merge Join
Efficient if tables do not fit in memory and both are sorted on the join attribute
Each tuple/block is read once.
If the tables are not sorted an external sort can be used.

Sort-merge join external sorting
Sorting large files is a balancing act that keeps only portions of the data in memory at any point in time
1. sorting phase
- Portions (runs) of a file that fit in memeory are sorted using an internal sorting algorithm
2. Merge phase
- The runs are merge in one or more passes.

External sorting is beyond the memory and uses the hard disk also.

Duplicate Elimination
- Can be perfomred by sorting the table and removeing adjacent duplicates.
- Hashing can also be used by hash partitioning the table, forming a memory resident hash index, checking for collisions and reetrieving the unique rows.

Set operations

Union intersection and set-difference can also be implemented by sorting and scanning both
UNION ALL does not remove dups so withour a sort it is much faster.
Another apporach is to hash parition the table build a memory resident hash index for the one table and check for collisions form the second table.

Materialization and Pipelining
Materialization means that intermediate results are physically instantited and used to evaluate parent operations in the query tree, Therefore the i/o costs of create the intermediate result must be added ot he cost estimates.

Pipelining reduces the number of intermediate results by dynamically passing the results of one or more operations to parent operations
- Demand-Driven Pipelines
- Producer-Driven Pipelines.

Anotated query tree has the operation implemntation as well as a execution plan.

Optimization Tradeoffs
The query engines determines which algorithm to use in teach case, based on the relative cost of each algorithm, this in term depens on selecteinvty

All other (non clusted) indexes of the index table contain values of clustering key instad of heap pointers.:w
Non cluster is iniffiecient compared to clustered index.
- Good candidates for clustered indexes are
- Primary keys of the lookup/reference/dimension/master tables.
- Foreign keys of the fact/detail tables.

Oracle OPTIMIZER_MODE
By default oracle chooses the least amount of resources necessary to process all rows accesed by the statement.  Oracle can also optimaize a statement with the goal of best response time.  This measn that it uses the least amount of resources necessary to process the first row accessed by a sql statemnent
The optimization goal can be set explicitly or expressed as query optimizer hints
`ALTER SESSION SET OPTIMIZER_MODE = FIRST_ROWS_1` optimize by getting first row
`/* ALL_ROWS using comment-like hint */` optimize by getting all rows
`RULE` RBO
`COST`: 
- `ALL_ROWS`: throughput
- `FIRT_ROWS_n`: response time
- `FIRST_ROWS` (olrder heuristic-based approach)

The stts nused by the query optimizer are stores in the data dictionary.  v$ in oracle.
You can collect exact or estimated stats about hysical storace haracterics and data by using DBMS_STATS package.

Optimizer Hints

There is a rich set of hints that can be specified at the query level, using a comment-like syntax
```
SELECT /*+ INDEX(persons) */ id, name
FROM persons
WHERE name = 'joe hacker';
```

View merging
Treating views as seperate query blocks can lead to suboptimal plans
The query of the view will execute before the main view is executed.

Execution Plans
If you are using CBO will use the selectivity of the index to guide usage

Syntactic considerations include
- No NULL values in Indexes, so IS NULL/ IS NOT NULL will not use indexes

Execution Plans
If you are using CBO will use the selectivity of the index to guide usage

Syntactic considerations include
- No NULL values in Indexes, so IS NULL/ IS NOT NULL will not use indexes.
- Point or range queries usually use indexes (selectivity)
- Leading wildcards do not use indexes
- Most functions on column will not use indexes except MIN MAX.
- Leading columns on composite indexes must be used

Good design trumps performance tuning
- Many problems are better addressed trhough design review and refinements

DB design issues and entity-relationship modeling techniques are out of scope of this document, even though flawed design can severly impact the performance in many ways.
