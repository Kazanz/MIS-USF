What is a transaction?

A transaction is a logical unit of work that includes one ore more executable statements which may access or update a collection of data items
- EIther the entire transaction executes or none of it does
  - reacll the ACID properties
- A database must be in a consisten and correct state both before and after the transaction executed.

A transaction reaches a commit point when all operations have executed succesffully and all effects have been writte to persistent storage.

ACID
====
Atomicity: Means either one or zero.  Everything or nothing will execute
    All or none of the operations are relcted in the database, no partial execution.

Consistency 
  Execution of a single transactions (not concurrent transactions) leaves the database in a consistent state.  Under programmer control with help from database constraints

Isolation: A particular users interactions wil not be dpeendent on other users interactions.
    Must have concurrency. multiple users or programs can use the db at the same time
    Even in a concurrent environment, each transaction executes as if it were the only transaction.  That is, each transation is unaware of the others, despite the fact that their operations may be interleaved.
    Isolated from reads? Isolated from writes?

Durability:  
    A successful transactions results in database changes that persist even in the face of system failures.


A transaction start implicitly whenever a DML (Data Manipulation Language) statement modifies the Data or explictly with `SET TRANSACTION`.
transactions end with TCL statements
    Commit: Save changes to the persistent database
    Rollback: Undo changes (using rollback segments)
    Savepoint: Specify points for partial rollbacks

An implicit commit is submitted before and after each DDL (Data Definition Language) statement (ex: CREATE, ALTER, DROP).

Read Consistency
Guarentees that the data being manipulated during a statement or transaction remains consistent, even if two transactions are using the same data.
SQL standard read consistency levels include (highest to lowest):
- serializable 
  Will do one transaction then the other, serializs the entire transaction then runs it.
- repeatable read (requires commit and no update)
  Will get the same value even if a write from a diff transaction is between the two reads in a single transactions.
- read committed
  Transactions will only read data that has been commited
- read uncommited
  Transactions will get the uncommited writes from other transactions, so if that transaction rollsback

If two transactions try to updat the same data, locking comes into play.
The database will not allow two transactions to access the same data at the same time.


# Oracle Read Consistency

Statement level (READ committed/write)
- Data is consistent during each statement/query
- Usually the default
- `SET TRANSACTION ISOLATION LEVEL READ COMMITTED`
Transaction Level (SERIALIZABLE/READ ONLY)
- Data is consistent during the life of the transaction.  All data is views as it existed when the transaction started.
- `SET TRANSACTION ISOLATION LEVEL SERIALIZABLE`

ORACLE automatically provides read consistency to a query so that all the data that the query sees comes form a single point in time (statement-level read consistency)
Oracle can also provide read consistency to all the queries in a transaction (transaction-level read consistency)
- Rollback segment sprovide an undo for database changes in the event of a ROLLBACK
- IN addition, rollback segments provide the "before" image necessary to maintain read consistency.


Undo/rollback segments play two important roles
1. Rollback segments provide a undo for database changes in the tansaction terminated with ROLLBACK.
2. Rollback segments also provide the before image necessary to maintina "read consistency".

Multiversion consistency model
Row Versioning-Based Isolation

Read-Write Tradeoff-Readers are more prone to larger analysis types of queries and writeers are more prone to singleotn insers updates deletes.


Parallel I/O Strategies
=======================

Increasing I/O Bandwidth through parallelism

Access Techniques
    Point Queries
    Range Queries
    Scan Queries

Paritioning Techniques
    Round-Robin Partitioning
        Parcel out nearly equal piles
        - Have nearly equal piles of tuples
        - retrieval tasks are balances across dissks if the answer set is large
        - Godd for full table scans
        - No attribute-value clustering
        - Not good for range queries
    Hash Partitioning
        Use a good hash function to distribute tuples base on a collection of partitioning attributes
        - A good hash function will evenly distribute tuples using partitioning attributes
        - Balanced retrieval tasks across disks
        - Good for sequential scnas
        - Good for point queries based on the partitioning attributes
        - No attribute-value clustering, so poor suppport for range queries
    Range Partitioning
        Distribute tuples based on a collection of paritioning attributes and ranges of values
        - Good for sequential scans
        - Good for point queries on partitioning attribute
        - Range queries localized for partitioning attribute.
          - Good if answer set is small (a few blocks).
          - If many blocks must be retrieved the paritioning becomes a hot spot.
          - Performance is best when the data is evenly distributed across partitions.
          - If there is unequal distribution you may want to consider one of the other methods of partitioning.
          - The problem is that you may have data skew or execution skew (all data or execution occurs in one hard disk)

In general hash partitiongin or range partitioning are prefered to round robin partitioning


```
CREATE TABLE q1_sales_by_region
(...)
PARTITION BY LIST (state)
    (PARTITION q1_northwest VALUES ('OR', 'WA')
     ));
```

Horizontal (Related Rows)
Verifcal (Related Columns)
- Speed
- Availability
- Used in 1000+ column tables usually

Load Balancing: Data skew
Data may be unevenly distributed between partitions (ie skewed) resulting in less than ideal gains through parallelism
- The higher the degree of parallelism the more sensitivity to skew
Partition Skew (Uneven Pils)
Attribute-Value Skew (Values within Piles)
Execution Skew
- Computational effore may be unevenly distributed between paritions (skewed) resulting in less than ideal gains through parallelsim.

Parallel Query Optimization

DEGREE means there are 4 partitions (or threads) INSTANCES the Oracle process that can only run on one processor

Sequential Execution
Parallel Execution
Query slaves to query coordinator

Dynamically partioned by DOP
Since the work may be unequally partitioned, subranges are formed for query slave assignment.

Creating partitioned tables provides benifits via the optimzer for both squential and parallel executin by reducing data volumnes
- However this static partitioning may not be the most approprate for specific parallel execution strategies.

Lots of query slaves returning lots of data can cause significant Communication Overhead
The SGA will hold and match the data form the query slaves before sendin it to the user.

Parallel DML
Parallel version of DML operations are enabled
- INSERT
- UPDATE
- DELETE

Can create Parallel CREATE INDEX (pCI)
